# -*- coding: utf-8 -*-
"""3LSTM_work.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CesuXhoMqdT2mk8G6goRmoXlltI9nnsu
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import math
from sklearn.preprocessing import MinMaxScaler 
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import mean_absolute_percentage_error

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NTC stock data.csv')
df.head()

df.Dates

df.set_index('Dates',inplace=True)

df

plt.figure(figsize=(15,8))
plt.title('Stock Price History')
plt.plot(df['Last_tp'])
plt.xlabel('Dates')
plt.ylabel('Prices')

close_prices = df['Last_tp']
#values = close_prices.values
close_prices = close_prices.str.replace(',', '') # remove commas
close_prices = close_prices.str.replace('[^0-9\.]', '') # remove non-numeric characters
values = close_prices.values.astype(float)

training_data_len = math.ceil(len(values)* 0.7)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(values.reshape(-1,1))

train_data = scaled_data[0: training_data_len, :]

x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    
x_train, y_train = np.array(x_train), np.array(y_train)

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

test_data = scaled_data[training_data_len-60: , : ]
x_test = []
y_test = values[training_data_len:]

for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i, 0])

x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

model = keras.Sequential()
model.add(layers.LSTM(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(layers.LSTM(100, return_sequences=False))
model.add(layers.Dense(25))
model.add(layers.Dense(1))
model.summary()

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(x_train, y_train, batch_size= 1, epochs=5)

predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
rmse = np.sqrt(np.mean(predictions - y_test)**2)
rmse

data = df.filter(['Last_tp'])
train = data[:training_data_len]
validation = data[training_data_len:]
validation['Predictions'] = predictions
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date')
plt.ylabel('Close Price')
# plt.plot(train)
# plt.plot(validation[['Last_tp', 'Predictions']])
# plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
# plt.show()
plt.plot(train.index, train['Last_tp'])
plt.plot(validation.index, validation['Last_tp'])
plt.plot(validation.index, validation['Predictions'])
plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
plt.show()

# Get the last 60 days of closing prices
last_60_days = df['Last_tp'][-60:].values.reshape(-1, 1)
last_60_days_scaled = scaler.transform(last_60_days)
future_predictions = []
for i in range(30):
    X_test = np.reshape(last_60_days_scaled, (1, last_60_days_scaled.shape[0], 1))
    y_pred = model.predict(X_test)
    y_pred_actual = scaler.inverse_transform(y_pred)
    future_predictions.append(y_pred_actual[0][0])
    last_60_days_scaled = np.vstack([last_60_days_scaled[1:], y_pred])

# Plot the predicted values
plt.figure(figsize=(16,8))
plt.plot(df['Last_tp'])
plt.plot(np.arange(len(df['Last_tp']), len(df['Last_tp']) + len(future_predictions)), future_predictions)
plt.title('Predicted Stock Prices')
plt.xlabel('Date')
plt.ylabel('Close Price')
plt.legend(['Actual', 'Predicted'])
plt.show()

start_date = pd.to_datetime('2023-01-13')
index = pd.date_range(start=start_date, periods=30, freq='D')
# future_predictions_df = pd.DataFrame({'Predicted': future_predictions.reshape(-1)}, index=index)
future_predictions = np.array(future_predictions)

# Reshape future_predictions
future_predictions = future_predictions.reshape(-1, 1)

# Create a DataFrame with the predicted values and index
future_predictions_df = pd.DataFrame({'Predicted': future_predictions[:, 0]}, index=index)

future_predictions_df

# Get actual values for last 30 days
actual_values = df['Last_tp'][-30:].values

# Calculate MAPE
mape = mean_absolute_percentage_error(actual_values, future_predictions) * 100

print("MAPE:", mape)



df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/NTC stock data.csv')
df.Dates
df.set_index('Dates',inplace=True)
close_prices = df['Last_tp']
#values = close_prices.values
close_prices = close_prices.str.replace(',', '') # remove commas
values = close_prices.values.astype(float)
training_data_len = math.ceil(len(values)* 0.7)

scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(values.reshape(-1,1))

train_data = scaled_data[0: training_data_len, :]

x_train = []
y_train = []

for i in range(60, len(train_data)):
    x_train.append(train_data[i-60:i, 0])
    y_train.append(train_data[i, 0])
    
x_train, y_train = np.array(x_train), np.array(y_train)

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
test_data = scaled_data[training_data_len-60: , : ]
x_test = []
y_test = values[training_data_len:]

for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i, 0])

x_test = np.array(x_test)
x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

model = keras.Sequential()
model.add(layers.SimpleRNN(100, return_sequences=True, input_shape=(x_train.shape[1], 1)))
model.add(layers.SimpleRNN(100))
model.add(layers.Dense(25))
model.add(layers.Dense(1))

model.summary()
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(x_train, y_train, batch_size= 1, epochs=5)

predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)
rmse = np.sqrt(np.mean(predictions - y_test)**2)
rmse

data = df.filter(['Last_tp'])
train = data[:training_data_len]
validation = data[training_data_len:]
validation['Predictions'] = predictions

# plt.figure(figsize=(16,8))
# plt.title('Model')
# plt.xlabel('Date')
# plt.ylabel('Close Price')
# plt.plot(train)
# plt.plot(validation[['Last_tp', 'Predictions']])
# plt.legend(['Train', 'Val', 'Predictions'], loc='lower right')
# plt.show()

# Get the last 60 days of closing prices
last_60_days = df['Last_tp'][-60:].values.reshape(-1, 1)
last_60_days_scaled = scaler.transform(last_60_days)

future_predictions = []
for i in range(30):
    X_test = np.reshape(last_60_days_scaled, (1, last_60_days_scaled.shape[0], 1))
    y_pred = model.predict(X_test)
    y_pred_actual = scaler.inverse_transform(y_pred)
    future_predictions.append(y_pred_actual[0][0])
    last_60_days_scaled = np.vstack([last_60_days_scaled[1:], y_pred])

# Plot the predicted values
# plt.figure(figsize=(16,8))
# plt.plot(df['Last_tp'])
# plt.plot(np.arange(len(df['Last_tp']), len(df['Last_tp']) + len(future_predictions)), future_predictions)
# plt.title('Predicted Stock Prices')
# plt.xlabel('Date')
# plt.ylabel('Close Price')
# plt.legend(['Actual', 'Predicted'])
# plt.show()

start_date = pd.to_datetime('2023-01-13')
index = pd.date_range(start=start_date, periods=30, freq='D')
# future_predictions_df = pd.DataFrame({'Predicted': future_predictions.reshape(-1)}, index=index)
future_predictions = np.array(future_predictions)

# Reshape future_predictions
future_predictions = future_predictions.reshape(-1, 1)

# Create a DataFrame with the predicted values and index
future_predictions_df = pd.DataFrame({'Predicted': future_predictions[:, 0]}, index=index)

# Get actual values for last 30 days
actual_values = df['Last_tp'][-30:].values

# Calculate MAPE
mape = mean_absolute_percentage_error(actual_values, future_predictions) * 100

print("MAPE:", mape)

